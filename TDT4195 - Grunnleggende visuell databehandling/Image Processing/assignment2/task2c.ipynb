{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3dccc3",
   "metadata": {},
   "source": [
    "# Visualizing filters in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"images/zebra.jpg\")\n",
    "plt.imshow(image)\n",
    "print(\"Image shape:\", image.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c6298",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example we will use a pre-trained ResNet50 network.\n",
    "# ResNet-50 is a fully-convolutional neural network that excels at image classification.\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5a4202",
   "metadata": {},
   "source": [
    "### First convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb07ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this task we are interested in visualizing the first convolutional layer. This can be retrieved by the following code block: \n",
    "first_conv_layer = model.conv1\n",
    "print(\"First conv layer weight shape:\", first_conv_layer.weight.shape)\n",
    "print(\"First conv layer:\", first_conv_layer)\n",
    "# Observe that it has 64 filters/kernels in the layer. Each kernel is a $7 \\times 7$ filter, that takes an RGB image as input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619231ff",
   "metadata": {},
   "source": [
    "### Activation from first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8184cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to resize, and normalize the image with the mean and standard deviation that they used to originally train this network.\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the image transform to the zebra image\n",
    "image = image_transform(image)[None]\n",
    "print(\"Image shape:\", image.shape)\n",
    "# By running the image through the first layer, we get an activation.\n",
    "# We can retrieve the activation from the first layer by doing a forward pass throught this conv layer.\n",
    "activation = first_conv_layer(image)\n",
    "print(\"Activation shape:\", activation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, we can retrieve the weight from the first convolution layer with the following:\n",
    "weight = model.conv1.weight.data.cpu()\n",
    "print(\"Filter/Weight/kernel size:\", weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a589dde4",
   "metadata": {},
   "source": [
    "### Visualize filters & Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32917a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_image_to_numpy(image: torch.Tensor):\n",
    "    \"\"\"\n",
    "        We've created a function `torch_image_to_numpy` to help you out.\n",
    "        This function transforms an torch tensor with shape (batch size, num channels, height, width) to\n",
    "        (batch size, height, width, num channels) numpy array\n",
    "    \"\"\"\n",
    "    # Normalize to [0 - 1.0]\n",
    "    image = image.detach().cpu() # Transform image to CPU memory (if on GPU VRAM)\n",
    "    image = image - image.min()\n",
    "    image = image / image.max()\n",
    "    image = image.numpy()\n",
    "    if len(image.shape) == 2: # Grayscale image, can just return\n",
    "        return image\n",
    "    assert image.shape[0] == 3, \"Expected color channel to be on first axis. Got: {}\".format(image.shape)\n",
    "    image = np.moveaxis(image, 0, 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fccfba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE HERE ### (You can change anything inside this block)\n",
    "# plt.subplot is a nice function to use for this task!\n",
    "# Tip: test out for indices = [01,2,3,4,5] to check that your result is correct!\n",
    "indices = [5, 8, 19, 22, 34]\n",
    "num_filters = len(indices)\n",
    "# %%\n",
    "plt.figure(figsize=(20, 4)) \n",
    "n = 1\n",
    "for i in indices:\n",
    "    plt.subplot(2, num_filters, n)\n",
    "    # Plot weight here\n",
    "    plt.subplot(2, num_filters, num_filters+n)\n",
    "    # Plot activation here\n",
    "    n += 1\n",
    "### END YOUR CODE HERE ###"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
