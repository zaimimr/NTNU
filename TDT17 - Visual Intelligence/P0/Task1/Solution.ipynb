{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(z):\n",
    "    return np.maximum(z,0)\n",
    "\n",
    "def d_ReLU(z):\n",
    "    return 1.0 * (z > 0)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "def d_sigmod(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "# Using log10\n",
    "def binary_cross_entropy(y_hat, y_pred):\n",
    "    return -1*(y_hat*np.log10(y_pred) + (1-y_hat)*np.log10(1-y_pred))\n",
    "\n",
    "def d_binary_cross_entrpoy(y_hat, y_pred):\n",
    "    return -1*(y_hat/y_pred - (1-y_hat)/(1-y_pred))\n",
    "\n",
    "def max_pool(input, kernel, stride):\n",
    "    z = np.zeros(((input.shape[0] - kernel) // stride + 1 , (input.shape[1] - kernel) // stride + 1)) \n",
    "    idx = []\n",
    "    \n",
    "    for x in range(z.shape[0]):\n",
    "        for y in range(z.shape[1]):\n",
    "            i = x*kernel\n",
    "            j = y*kernel\n",
    "            block = input[i : i+kernel, j : j+kernel] \n",
    "            z[x,y] = np.max(block)\n",
    "            index = np.add(np.unravel_index(block.argmax(), block.shape), (i, j))\n",
    "            idx.append(index)\n",
    "    return z, idx\n",
    "\n",
    "# Not using stride or padding for simplicity\n",
    "def convolution(input, kernel, bias):\n",
    "    output = np.zeros((input.shape[0] - kernel.shape[0] + 1, input.shape[1] - kernel.shape[1] + 1))\n",
    "    for i in range(output.shape[0]):\n",
    "        for j in range(output.shape[1]):\n",
    "            output[i, j] = np.sum(input[i:i+kernel.shape[0], j:j+kernel.shape[1]] * kernel) + bias\n",
    "    return output\n",
    "\n",
    "# Simple visualization function\n",
    "def printMatrix(A, text):\n",
    "    print(text)\n",
    "    print(A)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image\n",
      "[[1 2 0 2 1]\n",
      " [0 1 1 2 1]\n",
      " [1 2 0 1 0]\n",
      " [1 2 1 2 1]\n",
      " [0 0 3 2 3]]\n",
      "---\n",
      "Kernel\n",
      "[[ 1 -1]\n",
      " [-1  1]]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "input = np.array([[1,2,0,2,1], \n",
    "                  [0,1,1,2,1], \n",
    "                  [1,2,0,1,0], \n",
    "                  [1,2,1,2,1], \n",
    "                  [0,0,3,2,3]])\n",
    "\n",
    "kernel = np.array([[1,-1],\n",
    "                   [-1,1]])\n",
    "bias_conv = 1.0\n",
    "\n",
    "printMatrix(input, \"Input image\")\n",
    "printMatrix(kernel, \"Kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv\n",
      "[[ 1.  3.  0.  1.]\n",
      " [ 1. -1.  1.  1.]\n",
      " [ 1.  2.  1.  1.]\n",
      " [ 0.  5. -1.  3.]]\n",
      "---\n",
      "ReLU\n",
      "[[1. 3. 0. 1.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 2. 1. 1.]\n",
      " [0. 5. 0. 3.]]\n",
      "---\n",
      "Max Pool\n",
      "[[3. 1.]\n",
      " [5. 3.]]\n",
      "---\n",
      "Flatten\n",
      "[[3. 1. 5. 3.]]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "z_conv = convolution(input, kernel, bias_conv)\n",
    "\n",
    "a_relu = ReLU(z_conv)\n",
    "\n",
    "a_max_pool, idx_max = max_pool(a_relu, kernel.shape[0], stride=2)\n",
    "\n",
    "a_flatten = a_max_pool.flatten()\n",
    "\n",
    "printMatrix(z_conv, \"Conv\")\n",
    "printMatrix(a_relu, \"ReLU\")\n",
    "printMatrix(a_max_pool, \"Max Pool\")\n",
    "printMatrix(a_flatten.reshape(1,4), \"Flatten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation FCNN: 0.8807970779778823\n",
      "Binary cross-entropy loss: 0.05512413479491803\n"
     ]
    }
   ],
   "source": [
    "weight_fcnn = np.array([1, 1, -1, 1])\n",
    "bias_fcnn = 0\n",
    "\n",
    "z_fcnn = weight_fcnn.dot(a_flatten) + bias_fcnn\n",
    "a_fcnn = sigmoid(z_fcnn)\n",
    "loss = binary_cross_entropy(1, a_fcnn)\n",
    "print(f\"Activation FCNN: {a_fcnn}\")\n",
    "print(f\"Binary cross-entropy loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias Conv\n",
      "1.0\n",
      "---\n",
      "Kernel\n",
      "[[ 1 -1]\n",
      " [-1  1]]\n",
      "---\n",
      "Weight FCNN\n",
      "[ 1  1 -1  1]\n",
      "---\n",
      "Bias FCNN\n",
      "0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "printMatrix(bias_conv, \"Bias Conv\")\n",
    "printMatrix(kernel, \"Kernel\")\n",
    "printMatrix(weight_fcnn, \"Weight FCNN\")\n",
    "printMatrix(bias_fcnn, \"Bias FCNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL / d(bias_fcnn) = -0.11920292202211769\n",
      "dL / d(weight_fcnn) = [-0.35760877 -0.11920292 -0.59601461 -0.35760877]\n",
      "Reshaped derivative\n",
      "[[-0.35760877 -0.11920292]\n",
      " [-0.59601461 -0.35760877]]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "delta = d_binary_cross_entrpoy(1, a_fcnn) * d_sigmod(z_fcnn)\n",
    "print(f\"dL / d(bias_fcnn) = {delta}\")\n",
    "bias_fcnn = bias_fcnn - learning_rate * delta \n",
    "\n",
    "delta = delta * a_flatten \n",
    "print(f\"dL / d(weight_fcnn) = {delta}\") \n",
    "weight_fcnn = weight_fcnn - learning_rate * delta \n",
    "\n",
    "delta = delta.reshape(a_max_pool.shape) \n",
    "printMatrix(delta, \"Reshaped derivative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_relu\n",
      "[[1. 3. 0. 1.]\n",
      " [1. 0. 1. 1.]\n",
      " [1. 2. 1. 1.]\n",
      " [0. 5. 0. 3.]]\n",
      "---\n",
      "dL/d(a_relu)\n",
      "[[ 0.         -0.35760877  0.         -0.11920292]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.59601461  0.         -0.35760877]]\n",
      "---\n",
      "dL/d(z_conv)\n",
      "[[ 0.         -0.35760877  0.         -0.11920292]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.59601461  0.         -0.35760877]]\n",
      "---\n",
      "dL / d(grad_b1) = -1.4304350642654122\n"
     ]
    }
   ],
   "source": [
    "calculate_delta = np.zeros(a_relu.shape)\n",
    "\n",
    "for idx, grad in zip(idx_max, delta.flatten()): \n",
    "    calculate_delta[idx[0],idx[1]] = grad\n",
    "\n",
    "delta = calculate_delta\n",
    "printMatrix(a_relu, \"a_relu\") \n",
    "printMatrix(delta, \"dL/d(a_relu)\")\n",
    "\n",
    "delta = d_ReLU(z_conv) * delta \n",
    "printMatrix(delta, \"dL/d(z_conv)\")\n",
    "\n",
    "grad_b1 = delta.sum()\n",
    "print(f\"dL / d(grad_b1) = {grad_b1}\") \n",
    "bias_conv = bias_conv - learning_rate * grad_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/d(grad_kernel)\n",
      "[[-2.86087013 -1.0728263 ]\n",
      " [-1.31123214 -3.33768182]]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "grad_kernel = np.zeros(kernel.shape)\n",
    "\n",
    "grad_kernel[0,0] = np.sum(input[0:4, 0:4] * delta) \n",
    "grad_kernel[0,1] = np.sum(input[0:4, 1:5] * delta) \n",
    "grad_kernel[1,0] = np.sum(input[1:5, 0:4] * delta) \n",
    "grad_kernel[1,1] = np.sum(input[1:5, 1:5] * delta)\n",
    "\n",
    "kernel = kernel - learning_rate * grad_kernel\n",
    "printMatrix(grad_kernel, \"dL/d(grad_kernel)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weight FCNN\n",
      "[ 1.03576088  1.01192029 -0.94039854  1.03576088]\n",
      "---\n",
      "Updated Bias FCNN\n",
      "0.011920292202211769\n",
      "---\n",
      "Updated Kernel\n",
      "[[ 1.28608701 -0.89271737]\n",
      " [-0.86887679  1.33376818]]\n",
      "---\n",
      "Updated Bias Conv\n",
      "1.1430435064265412\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "printMatrix(weight_fcnn, \"Updated Weight FCNN\")\n",
    "printMatrix(bias_fcnn, \"Updated Bias FCNN\")\n",
    "printMatrix(kernel, \"Updated Kernel\")\n",
    "printMatrix(bias_conv, \"Updated Bias Conv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
